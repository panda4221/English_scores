{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45c64ce1",
   "metadata": {},
   "source": [
    "# English Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9781ef63",
   "metadata": {},
   "source": [
    "Просмотр фильмов на оригинальном языке - это популярный и действенный метод прокачаться при изучении иностранных языков. Важно выбрать фильм, который подходит студенту по уровню сложности, т.ч. студент понимал 50 - 70 % диалогов. Чтобы выполнить это условие, преподаватель должен посмотреть фильм и решить, какому уровню он соответствует. Однако это требует больших временных затрат.\n",
    "\n",
    "#### Задача проекта:\n",
    "\n",
    "Разработать ML решение для автоматического определения уровня сложности англоязычных фильмов.\n",
    "\n",
    "#### Вводные данные:\n",
    "1. Файл excel с указанием фильма и разметкой уровня языковой сложности.\n",
    "2. Субтитры к указанным в файле Excel.\n",
    "3. Папки с субтитрами, распределенные по разным уровням сложности."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d2d5e3",
   "metadata": {},
   "source": [
    "## 1. Загрузка данных\n",
    "\n",
    "Для начала загрузим все необходимые библиотеки и имеющиеся данные, на основании которых дулее будет происходить обучение модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76d9a07",
   "metadata": {},
   "source": [
    "pip install pysrt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d21ddc",
   "metadata": {},
   "source": [
    "pip install pymorphy2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299a95c2",
   "metadata": {},
   "source": [
    "pip uninstall nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4688c6c1",
   "metadata": {},
   "source": [
    "pip install -U nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a6d1eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\yulia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pysrt\n",
    "import codecs\n",
    "from sklearn.utils import shuffle\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.stem.porter import *\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier, Pool, cv\n",
    "from sklearn import metrics\n",
    "import re\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5d1620",
   "metadata": {},
   "source": [
    "- Загрузка excel с уровнями к каждому фильму\n",
    "\n",
    "Загрузим файл `movies_labels.xlsx` и посмотрим на его содержимое."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bf9cabb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Movie</th>\n",
       "      <th>Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10_Cloverfield_lane(2016)</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10_things_I_hate_about_you(1999)</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A_knights_tale(2001)</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A_star_is_born(2018)</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Aladdin(1992)</td>\n",
       "      <td>A2/A2+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>236</td>\n",
       "      <td>Matilda(2022)</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>237</td>\n",
       "      <td>Bullet train</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>238</td>\n",
       "      <td>Thor: love and thunder</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>239</td>\n",
       "      <td>Lightyear</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>240</td>\n",
       "      <td>The Grinch</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>241 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                             Movie   Level\n",
       "0      0         10_Cloverfield_lane(2016)      B1\n",
       "1      1  10_things_I_hate_about_you(1999)      B1\n",
       "2      2              A_knights_tale(2001)      B2\n",
       "3      3              A_star_is_born(2018)      B2\n",
       "4      4                     Aladdin(1992)  A2/A2+\n",
       "..   ...                               ...     ...\n",
       "236  236                     Matilda(2022)      C1\n",
       "237  237                      Bullet train      B1\n",
       "238  238            Thor: love and thunder      B2\n",
       "239  239                         Lightyear      B2\n",
       "240  240                        The Grinch      B1\n",
       "\n",
       "[241 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xlsx = pd.read_excel('movies_labels.xlsx')\n",
    "df_xlsx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deac6aa1",
   "metadata": {},
   "source": [
    "Данный файл содержит в себе название фильма и уровень сложности языка к нему. Поскльку файлы с субтитрами содержат в наименовании названия фильмов, мы сможем по дынной информации соотнести каждому субтитру уровень из файла excel.\n",
    "\n",
    "Поскольку одному фильму может быть присвоено сразу несколько уровней сложности, выберем для дальнейшего обучения самый первый указанный уровень сложности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66739d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Movie</th>\n",
       "      <th>Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10_Cloverfield_lane(2016)</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10_things_I_hate_about_you(1999)</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A_knights_tale(2001)</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A_star_is_born(2018)</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Aladdin(1992)</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>236</td>\n",
       "      <td>Matilda(2022)</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>237</td>\n",
       "      <td>Bullet train</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>238</td>\n",
       "      <td>Thor: love and thunder</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>239</td>\n",
       "      <td>Lightyear</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>240</td>\n",
       "      <td>The Grinch</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>241 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                             Movie Level\n",
       "0      0         10_Cloverfield_lane(2016)    B1\n",
       "1      1  10_things_I_hate_about_you(1999)    B1\n",
       "2      2              A_knights_tale(2001)    B2\n",
       "3      3              A_star_is_born(2018)    B2\n",
       "4      4                     Aladdin(1992)    A2\n",
       "..   ...                               ...   ...\n",
       "236  236                     Matilda(2022)    C1\n",
       "237  237                      Bullet train    B1\n",
       "238  238            Thor: love and thunder    B2\n",
       "239  239                         Lightyear    B2\n",
       "240  240                        The Grinch    B1\n",
       "\n",
       "[241 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_xlsx['Level'] = df_xlsx['Level'].str[0:2]\n",
    "df_xlsx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ecd02f",
   "metadata": {},
   "source": [
    "- Загрузка списка .srt файлов к файлу excel\n",
    "\n",
    "Загрузим файлы с субтитрами для фильмов из файла excel. Для этого сначала переберем полные пути к этим файлам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f1de9e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Path\n",
       "0    C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...\n",
       "1    C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...\n",
       "2    C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...\n",
       "3    C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...\n",
       "4    C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...\n",
       "..                                                 ...\n",
       "111  C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...\n",
       "112  C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...\n",
       "113  C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...\n",
       "114  C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...\n",
       "115  C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...\n",
       "\n",
       "[116 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Path(\"C:/Users/yulia/OneDrive/Документы/С рабочего стола/Проекты/Workshop_2/English_scores/Subtitles_all/Subtitles\")\n",
    "list_str = []\n",
    "\n",
    "for x in p.rglob(\"*\"):\n",
    "    list_str.append(str(x))\n",
    "df_srt = pd.DataFrame(list_str, columns = ['Path'])\n",
    "df_srt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d238cf3d",
   "metadata": {},
   "source": [
    "Добавим колонку `Movie` и обработаем в нее названия фильмов из папки с субтитрами, чтобы далее по ней можно было подтянуть для каждого субтитра уровень из первой таблицы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfd175ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>Movie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...</td>\n",
       "      <td>.DS_Store</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...</td>\n",
       "      <td>10_Cloverfield_lane(2016)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...</td>\n",
       "      <td>10_things_I_hate_about_you(1999)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...</td>\n",
       "      <td>Aladdin(1992)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...</td>\n",
       "      <td>All_dogs_go_to_heaven(1989)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...</td>\n",
       "      <td>Warm_bodies(2013)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...</td>\n",
       "      <td>Westworld_scenes_of_Dr_Robert_Ford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...</td>\n",
       "      <td>We_are_the_Millers(2013)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...</td>\n",
       "      <td>While_You_Were_Sleeping(1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...</td>\n",
       "      <td>Zootopia(2016)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Path  \\\n",
       "0    C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...   \n",
       "1    C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...   \n",
       "2    C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...   \n",
       "3    C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...   \n",
       "4    C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...   \n",
       "..                                                 ...   \n",
       "111  C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...   \n",
       "112  C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...   \n",
       "113  C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...   \n",
       "114  C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...   \n",
       "115  C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...   \n",
       "\n",
       "                                  Movie  \n",
       "0                             .DS_Store  \n",
       "1             10_Cloverfield_lane(2016)  \n",
       "2      10_things_I_hate_about_you(1999)  \n",
       "3                         Aladdin(1992)  \n",
       "4           All_dogs_go_to_heaven(1989)  \n",
       "..                                  ...  \n",
       "111                   Warm_bodies(2013)  \n",
       "112  Westworld_scenes_of_Dr_Robert_Ford  \n",
       "113            We_are_the_Millers(2013)  \n",
       "114       While_You_Were_Sleeping(1995)  \n",
       "115                      Zootopia(2016)  \n",
       "\n",
       "[116 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_column_movie(value):\n",
    "    val = value['Path']\n",
    "    val = val.replace('C:\\\\Users\\\\yulia\\\\OneDrive\\\\Документы\\\\С рабочего стола\\\\Проекты\\\\Workshop_2\\\\English_scores\\\\Subtitles_all\\\\Subtitles\\\\', '')     \n",
    "    val = val.replace('.srt', '')     \n",
    "    return val\n",
    "\n",
    "df_srt['Movie'] = df_srt.apply(add_column_movie, axis=1)\n",
    "df_srt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f5970e",
   "metadata": {},
   "source": [
    "- Добавление в список excel директорий их субтитов\n",
    "\n",
    "Получим единую таблицу, содержащую информацию об уровне фильма и местоположнии субтитра."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d857b238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Movie</th>\n",
       "      <th>Level</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10_Cloverfield_lane(2016)</td>\n",
       "      <td>B1</td>\n",
       "      <td>C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10_things_I_hate_about_you(1999)</td>\n",
       "      <td>B1</td>\n",
       "      <td>C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A_knights_tale(2001)</td>\n",
       "      <td>B2</td>\n",
       "      <td>C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A_star_is_born(2018)</td>\n",
       "      <td>B2</td>\n",
       "      <td>C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Aladdin(1992)</td>\n",
       "      <td>A2</td>\n",
       "      <td>C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>107</td>\n",
       "      <td>Venom(2018)</td>\n",
       "      <td>B2</td>\n",
       "      <td>C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>108</td>\n",
       "      <td>Warm_bodies(2013)</td>\n",
       "      <td>B1</td>\n",
       "      <td>C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>109</td>\n",
       "      <td>We_are_the_Millers(2013)</td>\n",
       "      <td>B1</td>\n",
       "      <td>C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>110</td>\n",
       "      <td>While_You_Were_Sleeping(1995)</td>\n",
       "      <td>B1</td>\n",
       "      <td>C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>111</td>\n",
       "      <td>Zootopia(2016)</td>\n",
       "      <td>B2</td>\n",
       "      <td>C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                             Movie Level  \\\n",
       "0      0         10_Cloverfield_lane(2016)    B1   \n",
       "1      1  10_things_I_hate_about_you(1999)    B1   \n",
       "2      2              A_knights_tale(2001)    B2   \n",
       "3      3              A_star_is_born(2018)    B2   \n",
       "4      4                     Aladdin(1992)    A2   \n",
       "..   ...                               ...   ...   \n",
       "105  107                       Venom(2018)    B2   \n",
       "106  108                 Warm_bodies(2013)    B1   \n",
       "107  109          We_are_the_Millers(2013)    B1   \n",
       "108  110     While_You_Were_Sleeping(1995)    B1   \n",
       "109  111                    Zootopia(2016)    B2   \n",
       "\n",
       "                                                  Path  \n",
       "0    C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...  \n",
       "1    C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...  \n",
       "2    C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...  \n",
       "3    C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...  \n",
       "4    C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...  \n",
       "..                                                 ...  \n",
       "105  C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...  \n",
       "106  C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...  \n",
       "107  C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...  \n",
       "108  C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...  \n",
       "109  C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего с...  \n",
       "\n",
       "[110 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fin = df_xlsx.merge(df_srt, left_on='Movie', right_on='Movie')\n",
    "df_fin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc5386b",
   "metadata": {},
   "source": [
    "Теперь мы можем произвести непосредственную загрузу содержимого файлов с субтритрами по их полному пути хранения. Для перебора всей таблицы сделаем отдельную функцию.\n",
    "\n",
    "Поскольку далее нам понадобятся только колонки `Srt` с субтитрами и `Level` с уровнем английского, выберем только их. Выведем получившийся результат на экран."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b3fc829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Srt</th>\n",
       "      <th>Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;font color=\"#ffff80\"&gt;&lt;b&gt;Fixed &amp; Synced by bo...</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hey! I'll be right with you. So, Cameron. Her...</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Resync: Xenzai[NEF] RETAIL Should we help him...</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>- &lt;i&gt;&lt;font color=\"#ffffff\"&gt; Synced and correc...</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;i&gt;Oh, I come from a land From a faraway plac...</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>&lt;i&gt;Life Foundation Control, this is LF1.&lt;/i&gt; ...</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>&lt;i&gt;What am I doing&lt;/i&gt; &lt;i&gt;with my life?&lt;/i&gt; &lt;...</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>&lt;i&gt;Oh, my God...&lt;/i&gt; &lt;i&gt;...it's full-on doubl...</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>LUCY: &lt;i&gt;Okay, there are two things that&lt;/i&gt; ...</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Fear. Treachery Bloodlust. Thousands of years...</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Srt Level\n",
       "0     <font color=\"#ffff80\"><b>Fixed & Synced by bo...    B1\n",
       "1     Hey! I'll be right with you. So, Cameron. Her...    B1\n",
       "2     Resync: Xenzai[NEF] RETAIL Should we help him...    B2\n",
       "3     - <i><font color=\"#ffffff\"> Synced and correc...    B2\n",
       "4     <i>Oh, I come from a land From a faraway plac...    A2\n",
       "..                                                 ...   ...\n",
       "105   <i>Life Foundation Control, this is LF1.</i> ...    B2\n",
       "106   <i>What am I doing</i> <i>with my life?</i> <...    B1\n",
       "107   <i>Oh, my God...</i> <i>...it's full-on doubl...    B1\n",
       "108   LUCY: <i>Okay, there are two things that</i> ...    B1\n",
       "109   Fear. Treachery Bloodlust. Thousands of years...    B2\n",
       "\n",
       "[110 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_column_srt(value):\n",
    "    file = str(value['Path'].replace('\\\\', '/'))\n",
    "    text = ''    \n",
    "    subs = pysrt.open(file, encoding='iso-8859-1')\n",
    "    srt = ''\n",
    "    for sub in subs:\n",
    "        srt = srt + ' ' + sub.text\n",
    "     \n",
    "    return srt.replace('\\n', ' ')\n",
    "\n",
    "df_fin['Srt'] = df_fin.apply(add_column_srt, axis=1)\n",
    "df_fin = df_fin[['Srt','Level']]\n",
    "df_fin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b218b22",
   "metadata": {},
   "source": [
    "- Загрузка субтитров из папок по уровням английского языка\n",
    "\n",
    "Поскольку у нас также имеются папки по уровням английского языка, содержащие субтитры, загрузим их в отдельную таблицу с аналогичной структурой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "139c1d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_column_level(value):\n",
    "    val = value['Path'].split('\\\\')\n",
    "    return val[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3561714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Srt</th>\n",
       "      <th>Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>( bugs chittering ) ( brakes squeak ) - ( eng...</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>- ( birds chirping ) - ( bugs chittering ) Bo...</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>( thunder rumbling ) Merle: That's right. You...</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>( birds chirping ) - What? - Nothing. It's no...</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>- ( walkie-talkie squawks ) - Rick: Morgan, I...</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>I lost Ava her company. I assume my deal with...</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>Previously on &lt;i&gt;Suits...&lt;/i&gt; It's going up o...</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>I get Ava Hessington acquitted, Darby backs m...</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Previously on &lt;i&gt;Suits...&lt;/i&gt; I'm bonding wit...</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>Previously on &lt;i&gt;Suits...&lt;/i&gt; This is a copy ...</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Srt Level\n",
       "0     ( bugs chittering ) ( brakes squeak ) - ( eng...    A2\n",
       "1     - ( birds chirping ) - ( bugs chittering ) Bo...    A2\n",
       "2     ( thunder rumbling ) Merle: That's right. You...    A2\n",
       "3     ( birds chirping ) - What? - Nothing. It's no...    A2\n",
       "4     - ( walkie-talkie squawks ) - Rick: Morgan, I...    A2\n",
       "..                                                 ...   ...\n",
       "158   I lost Ava her company. I assume my deal with...    C1\n",
       "159   Previously on <i>Suits...</i> It's going up o...    C1\n",
       "160   I get Ava Hessington acquitted, Darby backs m...    C1\n",
       "161   Previously on <i>Suits...</i> I'm bonding wit...    C1\n",
       "162   Previously on <i>Suits...</i> This is a copy ...    C1\n",
       "\n",
       "[163 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_str = []\n",
    "level_list = ['A2', 'B1', 'B2', 'C1']\n",
    "\n",
    "for level in level_list:\n",
    "    p = Path(\"C:/Users/yulia/OneDrive/Документы/С рабочего стола/Проекты/Workshop_2/English_scores/Subtitles_all\"+\"/\"+level)\n",
    "    for x in p.rglob(\"*\"):\n",
    "        list_str.append(str(x))\n",
    "        \n",
    "df_add = pd.DataFrame(list_str, columns = ['Path'])\n",
    "\n",
    "df_add['Srt'] = df_add.apply(add_column_srt, axis=1)\n",
    "df_add['Level'] = df_add.apply(add_column_level, axis=1)\n",
    "df_add = df_add[['Srt', 'Level']]\n",
    "df_add"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1b84ec",
   "metadata": {},
   "source": [
    "- Соединяем 2 таблицы\n",
    "\n",
    "Теперь мы можем соединить две таблицы для получения большего пула данных для обучения нашей модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "501e6e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Srt</th>\n",
       "      <th>Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;font color=\"#ffff80\"&gt;&lt;b&gt;Fixed &amp; Synced by bo...</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hey! I'll be right with you. So, Cameron. Her...</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Resync: Xenzai[NEF] RETAIL Should we help him...</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>- &lt;i&gt;&lt;font color=\"#ffffff\"&gt; Synced and correc...</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;i&gt;Oh, I come from a land From a faraway plac...</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>I lost Ava her company. I assume my deal with...</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>Previously on &lt;i&gt;Suits...&lt;/i&gt; It's going up o...</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>I get Ava Hessington acquitted, Darby backs m...</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Previously on &lt;i&gt;Suits...&lt;/i&gt; I'm bonding wit...</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>Previously on &lt;i&gt;Suits...&lt;/i&gt; This is a copy ...</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>273 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Srt Level\n",
       "0     <font color=\"#ffff80\"><b>Fixed & Synced by bo...    B1\n",
       "1     Hey! I'll be right with you. So, Cameron. Her...    B1\n",
       "2     Resync: Xenzai[NEF] RETAIL Should we help him...    B2\n",
       "3     - <i><font color=\"#ffffff\"> Synced and correc...    B2\n",
       "4     <i>Oh, I come from a land From a faraway plac...    A2\n",
       "..                                                 ...   ...\n",
       "158   I lost Ava her company. I assume my deal with...    C1\n",
       "159   Previously on <i>Suits...</i> It's going up o...    C1\n",
       "160   I get Ava Hessington acquitted, Darby backs m...    C1\n",
       "161   Previously on <i>Suits...</i> I'm bonding wit...    C1\n",
       "162   Previously on <i>Suits...</i> This is a copy ...    C1\n",
       "\n",
       "[273 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full = pd.concat([df_fin, df_add])\n",
    "df_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e94a78",
   "metadata": {},
   "source": [
    "Удалим все пустые значения, перемешаем данные и пересчитаем индексы.\n",
    "\n",
    "Также первоначальные данные содержат следующие уровни английского языка: `A2`, `B1`, `B2`, `C1`. Для удобства классифицируем уровень `A2` как `A1-A2`, а `C1` как `C1-C2`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "186c08b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_level(value):\n",
    "    val = value['Level']\n",
    "    val = val.replace('A2', 'A1-A2')\n",
    "    val = val.replace('C1', 'C1-C2')\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2100f566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Srt</th>\n",
       "      <th>Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(CROWD CHEERING) The Break-Up The Break-Up Co...</td>\n",
       "      <td>A1-A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Goddamn bugs. Oh, shit! Oh, crap. Well, Nick ...</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;b&gt;Resync By&lt;br/&gt;Lututkanan@subscene&lt;/b&gt; Do y...</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Here's something that should hurt your brain....</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Well, I wake up in the mornin' Each and every...</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>Asia - the largest of all the Earth's contine...</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>I hear you're interviewing replacements this ...</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>&lt;i&gt;GUARD: One con under escort. Open gate one...</td>\n",
       "      <td>C1-C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>(BUZZING) (BUZZING LOUDLY) VALIENTE: Show me ...</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>200 million years ago, our planet looked very...</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>257 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Srt  Level\n",
       "0     (CROWD CHEERING) The Break-Up The Break-Up Co...  A1-A2\n",
       "1     Goddamn bugs. Oh, shit! Oh, crap. Well, Nick ...     B1\n",
       "2     <b>Resync By<br/>Lututkanan@subscene</b> Do y...     B1\n",
       "3     Here's something that should hurt your brain....     B1\n",
       "4     Well, I wake up in the mornin' Each and every...     B1\n",
       "..                                                 ...    ...\n",
       "252   Asia - the largest of all the Earth's contine...     B1\n",
       "253   I hear you're interviewing replacements this ...     B2\n",
       "254   <i>GUARD: One con under escort. Open gate one...  C1-C2\n",
       "255   (BUZZING) (BUZZING LOUDLY) VALIENTE: Show me ...     B1\n",
       "256   200 million years ago, our planet looked very...     B1\n",
       "\n",
       "[257 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = shuffle(df_full[df_full['Srt']!='']).reset_index(drop=True)\n",
    "df['Level'] = df.apply(replace_level, axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546cf9e9",
   "metadata": {},
   "source": [
    "## 2. Подготовка данных к обучению"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb434c3c",
   "metadata": {},
   "source": [
    "- Удаление лишних символов\n",
    "\n",
    "В рамках проведения анализов субтитров были выявлены символы и строки, не несущие в себе смысловой нагрузки и засоряющие данные для обучения модели. Это какие-либо дополнительные сведения о создателе субтитров, веб-сайты, предоставившие субтитры бесплатно, а также технические символы.\n",
    "\n",
    "После обработки выведем наш датафрейм и посмотрим, как он изменился."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62f7e42c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Srt</th>\n",
       "      <th>Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(crowd cheering) the break-up the break-up co...</td>\n",
       "      <td>A1-A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>goddamn bugs. oh, shit! oh, crap. well, nick ...</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>resync by&lt;br/&gt;lututkanan@subscene  do you ha...</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>here's something that should hurt your brain....</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>well, i wake up in the mornin' each and every...</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>asia - the largest of all the earth's contine...</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>i hear you're interviewing replacements this ...</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>guard: one con under escort. open gate one. ...</td>\n",
       "      <td>C1-C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>(buzzing) (buzzing loudly) valiente: show me ...</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>200 million years ago, our planet looked very...</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>257 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Srt  Level\n",
       "0     (crowd cheering) the break-up the break-up co...  A1-A2\n",
       "1     goddamn bugs. oh, shit! oh, crap. well, nick ...     B1\n",
       "2      resync by<br/>lututkanan@subscene  do you ha...     B1\n",
       "3     here's something that should hurt your brain....     B1\n",
       "4     well, i wake up in the mornin' each and every...     B1\n",
       "..                                                 ...    ...\n",
       "252   asia - the largest of all the earth's contine...     B1\n",
       "253   i hear you're interviewing replacements this ...     B2\n",
       "254    guard: one con under escort. open gate one. ...  C1-C2\n",
       "255   (buzzing) (buzzing loudly) valiente: show me ...     B1\n",
       "256   200 million years ago, our planet looked very...     B1\n",
       "\n",
       "[257 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def replace_str(value):\n",
    "    val = value['Srt']\n",
    "    val = val.replace('ahmedhamdy90', ' ')\n",
    "    val = val.replace('subscene.com @ahmedhamdy2121', ' ')\n",
    "    val = val.replace('https://twitter.com/kaboomskull', ' ')\n",
    "    val = val.replace('shokomovies.blogspot.com', ' ')\n",
    "    val = val.replace('UNRATED.720p.BluRay.x264-REFiNED.English Upload to subscene.com by ViSTAâ\\x84¢-HDVN', ' ')\n",
    "    val = val.replace('www.YIFY-TORRENTS.com', ' ')\n",
    "    val = val.replace('www.ncicap.org', ' ')\n",
    "    val = val.replace('truecostmovie.com', ' ')\n",
    "    val = val.replace('Created and Encoded by --  Bokutox -- of  www.YIFY-TORRENTS.com. The Best 720p/1080p/3d movies with the lowest file size on the internet.', ' ')\n",
    "    val = val.replace('www.facemash.com', ' ')\n",
    "    val = val.replace('www.OpenSubtitles.org', ' ')\n",
    "    val = val.replace('www.titlovi.com', ' ')\n",
    "    val = val.replace('www.AllSubs.org', ' ')\n",
    "    val = val.replace('www.flixify.app', ' ')\n",
    "    val = val.replace('truecostmovie.com', ' ')\n",
    "    val = val.replace('teenybikini.com', ' ')\n",
    "\n",
    "    val = val.lower()\n",
    "\n",
    "    val = val.replace('font', ' ')\n",
    "    val = val.replace('color', ' ')\n",
    "    val = val.replace('ffff', ' ')\n",
    "    val = val.replace('<b>', ' ')\n",
    "    val = val.replace('</b>', ' ')\n",
    "    val = val.replace('<i>', ' ')\n",
    "    val = val.replace('</i>', ' ')\n",
    "    val = val.replace('font color', ' ')\n",
    "    val = val.replace('</font>', ' ')\n",
    "    val = val.replace('â\\x99ª', ' ')\n",
    "    val = val.replace('d900d9', ' ')\n",
    "    val = val.replace('âª', ' ')\n",
    "    \n",
    "    return val\n",
    "\n",
    "df['Srt'] = df.apply(replace_str, axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed1ff5d",
   "metadata": {},
   "source": [
    "- Лемматизация\n",
    "\n",
    "Лемматизация – это алгоритмический процесс нахождения леммы слова в зависимости от его значения. Лемматизация обычно относится к морфологическому анализу слов, целью которого является удаление флективных окончаний. Это помогает в возвращении базовой или словарной формы слова, которое известно как лемма. Метод лемматизации NLTK основан на встроенной морф-функции WorldNet. Предварительная обработка текста включает в себя как основы, так и лемматизации.\n",
    "\n",
    "Проведем лемматизацию для наших субтитров, а также избавимся от лишних символов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68286fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Srt</th>\n",
       "      <th>Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[crowd, cheering, break, break, come, come, co...</td>\n",
       "      <td>A1-A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[goddamn, bugs, oh, shit, oh, crap, well, nick...</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[resync, br, lututkanan, subscene, idea, br, a...</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[something, hurt, brain, empty, half, beds, ho...</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[well, wake, mornin, every, day, sit, table, h...</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>[asia, largest, earth, continents, stretches, ...</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>[hear, interviewing, replacements, morning, go...</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>[guard, one, con, escort, open, gate, one, gat...</td>\n",
       "      <td>C1-C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>[buzzing, buzzing, loudly, valiente, show, got...</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>[million, years, ago, planet, looked, differen...</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>257 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Srt  Level\n",
       "0    [crowd, cheering, break, break, come, come, co...  A1-A2\n",
       "1    [goddamn, bugs, oh, shit, oh, crap, well, nick...     B1\n",
       "2    [resync, br, lututkanan, subscene, idea, br, a...     B1\n",
       "3    [something, hurt, brain, empty, half, beds, ho...     B1\n",
       "4    [well, wake, mornin, every, day, sit, table, h...     B1\n",
       "..                                                 ...    ...\n",
       "252  [asia, largest, earth, continents, stretches, ...     B1\n",
       "253  [hear, interviewing, replacements, morning, go...     B2\n",
       "254  [guard, one, con, escort, open, gate, one, gat...  C1-C2\n",
       "255  [buzzing, buzzing, loudly, valiente, show, got...     B1\n",
       "256  [million, years, ago, planet, looked, differen...     B1\n",
       "\n",
       "[257 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patterns = \"[0-9!#$%&'()*+,./:;<=>?@[\\]^_`{|}~—\\\"\\-]+\"\n",
    "stopwords_en = stopwords.words(\"english\")\n",
    "morph = MorphAnalyzer()\n",
    "\n",
    "def lemmatize(doc):\n",
    "    doc = re.sub(patterns, ' ', doc)\n",
    "    tokens = []\n",
    "    for token in doc.split():\n",
    "        if token and token not in stopwords_en:\n",
    "            token = token.strip()\n",
    "            token = morph.normal_forms(token)[0]\n",
    "            \n",
    "            tokens.append(token)\n",
    "    if len(tokens) > 2:\n",
    "        return tokens\n",
    "    return None\n",
    "\n",
    "df['Srt'] = df['Srt'].apply(lemmatize)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a640ca93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Srt</th>\n",
       "      <th>Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>crowd cheering break break come come come righ...</td>\n",
       "      <td>A1-A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>goddamn bugs oh shit oh crap well nick dick su...</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>resync br lututkanan subscene idea br arguing ...</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>something hurt brain empty half beds hospitals...</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>well wake mornin every day sit table hear dadd...</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>asia largest earth continents stretches equato...</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>hear interviewing replacements morning good gr...</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>guard one con escort open gate one gate opens ...</td>\n",
       "      <td>C1-C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>buzzing buzzing loudly valiente show got bones...</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>million years ago planet looked different toda...</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>257 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Srt  Level\n",
       "0    crowd cheering break break come come come righ...  A1-A2\n",
       "1    goddamn bugs oh shit oh crap well nick dick su...     B1\n",
       "2    resync br lututkanan subscene idea br arguing ...     B1\n",
       "3    something hurt brain empty half beds hospitals...     B1\n",
       "4    well wake mornin every day sit table hear dadd...     B1\n",
       "..                                                 ...    ...\n",
       "252  asia largest earth continents stretches equato...     B1\n",
       "253  hear interviewing replacements morning good gr...     B2\n",
       "254  guard one con escort open gate one gate opens ...  C1-C2\n",
       "255  buzzing buzzing loudly valiente show got bones...     B1\n",
       "256  million years ago planet looked different toda...     B1\n",
       "\n",
       "[257 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lem_back(plurals):\n",
    "    singles = [plural for plural in plurals]\n",
    "    return (' '.join(singles))\n",
    "\n",
    "df['Srt'] = df['Srt'].apply(lem_back)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4936e605",
   "metadata": {},
   "source": [
    "- Оценка релевантности слов с помощью частотно-обратной частоты термина в документе\n",
    "\n",
    "Теперь переведем получившиеся данные в понятный модели язык - оценим релевантность слов с помощью частотно-обратной частоты термина в документе, используя для этого `TfidfTransformer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49d73f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = np.array(df['Srt'])\n",
    "pipe = Pipeline([('count', CountVectorizer()),\n",
    "                ('tfid', TfidfTransformer(use_idf=True, norm='l2', smooth_idf=True))]).fit(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e62dd542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>33418</th>\n",
       "      <th>33419</th>\n",
       "      <th>33420</th>\n",
       "      <th>33421</th>\n",
       "      <th>33422</th>\n",
       "      <th>33423</th>\n",
       "      <th>33424</th>\n",
       "      <th>33425</th>\n",
       "      <th>33426</th>\n",
       "      <th>Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007707</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A1-A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>0.007783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>C1-C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>257 rows × 33428 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0    1    2    3    4    5    6    7    8    9  ...  33418  33419  \\\n",
       "0    0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "1    0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "2    0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "3    0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "4    0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "..        ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...    ...   \n",
       "252  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "253  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "254  0.007783  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "255  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "256  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "\n",
       "        33420  33421  33422  33423  33424  33425  33426  Level  \n",
       "0    0.007707    0.0    0.0    0.0    0.0    0.0    0.0  A1-A2  \n",
       "1    0.000000    0.0    0.0    0.0    0.0    0.0    0.0     B1  \n",
       "2    0.000000    0.0    0.0    0.0    0.0    0.0    0.0     B1  \n",
       "3    0.000000    0.0    0.0    0.0    0.0    0.0    0.0     B1  \n",
       "4    0.000000    0.0    0.0    0.0    0.0    0.0    0.0     B1  \n",
       "..        ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "252  0.000000    0.0    0.0    0.0    0.0    0.0    0.0     B1  \n",
       "253  0.000000    0.0    0.0    0.0    0.0    0.0    0.0     B2  \n",
       "254  0.000000    0.0    0.0    0.0    0.0    0.0    0.0  C1-C2  \n",
       "255  0.000000    0.0    0.0    0.0    0.0    0.0    0.0     B1  \n",
       "256  0.000000    0.0    0.0    0.0    0.0    0.0    0.0     B1  \n",
       "\n",
       "[257 rows x 33428 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = pd.DataFrame(pipe.transform(docs).toarray())\n",
    "df_srt = pd.DataFrame(tfidf)\n",
    "df_srt['Level'] = df['Level']\n",
    "df_srt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb740660",
   "metadata": {},
   "source": [
    "## 3. Обучение модели\n",
    "Признаком для обучения нашей модели будут преобразованные субтитры, целевой признак - уровни английского языка из колонки `Level`. Разобьем данные на обучающие и тестовые."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4cc100b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_srt.drop(['Level'], axis=1)\n",
    "y = df_srt['Level']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d60259",
   "metadata": {},
   "source": [
    "В рамках данного проекта был выбран инструмент `CatBoostClassifier`, который поможет нам решить задачу мультиклассификации.\n",
    "Для этого поместим признаки в `Pool` для обучения нашей модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92889b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_pool = Pool(\n",
    "    X_train, \n",
    "    y_train\n",
    ")\n",
    "\n",
    "test_pool = Pool(\n",
    "    X_test, \n",
    "    y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcef336",
   "metadata": {},
   "source": [
    "- Кросс-валидация и подбор гипер-параметра\n",
    "\n",
    "Используем кросс-валидацию от CatBoost с `3` бакетами и подберем гиперпараметр `learning_rate` с наиболее высоким показателем среднего `F1` по результатам кросс-валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a34d6993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "learning_rate: 0.1\n",
      "\n",
      "Training on fold [0/3]\n",
      "0:\tlearn: 0.6084210\ttest: 0.3181818\tbest: 0.3181818 (0)\ttotal: 1.32s\tremaining: 22m 3s\n",
      "100:\tlearn: 0.9920265\ttest: 0.4964034\tbest: 0.4970896 (91)\ttotal: 1m 40s\tremaining: 14m 53s\n",
      "200:\tlearn: 0.9920265\ttest: 0.5550661\tbest: 0.5559157 (161)\ttotal: 3m 15s\tremaining: 12m 56s\n",
      "300:\tlearn: 0.9920978\ttest: 0.5550661\tbest: 0.5559157 (161)\ttotal: 4m 55s\tremaining: 11m 26s\n",
      "\n",
      "bestTest = 0.5559157352\n",
      "bestIteration = 161\n",
      "\n",
      "Training on fold [1/3]\n",
      "0:\tlearn: 0.5844597\ttest: 0.4078664\tbest: 0.4078664 (0)\ttotal: 1.06s\tremaining: 17m 38s\n",
      "100:\tlearn: 1.0000000\ttest: 0.5207888\tbest: 0.5362592 (95)\ttotal: 1m 44s\tremaining: 15m 27s\n",
      "200:\tlearn: 1.0000000\ttest: 0.5596967\tbest: 0.5732590 (142)\ttotal: 3m 23s\tremaining: 13m 30s\n",
      "300:\tlearn: 1.0000000\ttest: 0.5822030\tbest: 0.6036005 (224)\ttotal: 5m 1s\tremaining: 11m 39s\n",
      "400:\tlearn: 1.0000000\ttest: 0.6036005\tbest: 0.6036005 (224)\ttotal: 6m 42s\tremaining: 10m 1s\n",
      "\n",
      "bestTest = 0.6036005435\n",
      "bestIteration = 224\n",
      "\n",
      "Training on fold [2/3]\n",
      "0:\tlearn: 0.5361439\ttest: 0.3880136\tbest: 0.3880136 (0)\ttotal: 1.78s\tremaining: 29m 41s\n",
      "100:\tlearn: 1.0000000\ttest: 0.4327608\tbest: 0.4557926 (72)\ttotal: 1m 40s\tremaining: 14m 51s\n",
      "200:\tlearn: 1.0000000\ttest: 0.5231314\tbest: 0.5231314 (184)\ttotal: 3m 16s\tremaining: 13m 1s\n",
      "300:\tlearn: 1.0000000\ttest: 0.5239984\tbest: 0.5239984 (292)\ttotal: 4m 55s\tremaining: 11m 25s\n",
      "400:\tlearn: 1.0000000\ttest: 0.5239984\tbest: 0.5239984 (292)\ttotal: 6m 31s\tremaining: 9m 45s\n",
      "\n",
      "bestTest = 0.5239984078\n",
      "bestIteration = 292\n",
      "\n",
      "     iterations  test-TotalF1-mean  test-TotalF1-std  train-TotalF1-mean  \\\n",
      "346         346           0.560888          0.040119            0.997366   \n",
      "347         347           0.560888          0.040119            0.997366   \n",
      "348         348           0.560888          0.040119            0.997366   \n",
      "349         349           0.560888          0.040119            0.997366   \n",
      "350         350           0.560888          0.040119            0.997366   \n",
      "351         351           0.560888          0.040119            0.997366   \n",
      "354         354           0.560888          0.040119            0.997366   \n",
      "355         355           0.560888          0.040119            0.997366   \n",
      "356         356           0.560888          0.040119            0.997366   \n",
      "357         357           0.560888          0.040119            0.997366   \n",
      "358         358           0.560888          0.040119            0.997366   \n",
      "\n",
      "     train-TotalF1-std  test-MultiClass-mean  test-MultiClass-std  \\\n",
      "346           0.004562              0.940298             0.053119   \n",
      "347           0.004562              0.940975             0.053299   \n",
      "348           0.004562              0.941076             0.053401   \n",
      "349           0.004562              0.941289             0.053137   \n",
      "350           0.004562              0.941767             0.052696   \n",
      "351           0.004562              0.941780             0.052635   \n",
      "354           0.004562              0.940792             0.052527   \n",
      "355           0.004562              0.941050             0.052904   \n",
      "356           0.004562              0.941127             0.054008   \n",
      "357           0.004562              0.941224             0.054157   \n",
      "358           0.004562              0.941192             0.054505   \n",
      "\n",
      "     train-MultiClass-mean  train-MultiClass-std  \n",
      "346               0.037602              0.009143  \n",
      "347               0.037388              0.009141  \n",
      "348               0.037248              0.009213  \n",
      "349               0.037142              0.009258  \n",
      "350               0.037033              0.009285  \n",
      "351               0.036896              0.009294  \n",
      "354               0.036508              0.009281  \n",
      "355               0.036406              0.009295  \n",
      "356               0.036304              0.009291  \n",
      "357               0.036167              0.009247  \n",
      "358               0.036051              0.009250  \n",
      "\n",
      "\n",
      "learning_rate: 0.2\n",
      "\n",
      "Training on fold [0/3]\n",
      "0:\tlearn: 0.6084210\ttest: 0.3181818\tbest: 0.3181818 (0)\ttotal: 1.12s\tremaining: 18m 40s\n",
      "100:\tlearn: 0.9920265\ttest: 0.5360528\tbest: 0.5648019 (58)\ttotal: 1m 38s\tremaining: 14m 38s\n",
      "200:\tlearn: 0.9920265\ttest: 0.5529450\tbest: 0.5648019 (58)\ttotal: 3m 22s\tremaining: 13m 23s\n",
      "\n",
      "bestTest = 0.5648018648\n",
      "bestIteration = 58\n",
      "\n",
      "Training on fold [1/3]\n",
      "0:\tlearn: 0.5844597\ttest: 0.4078664\tbest: 0.4078664 (0)\ttotal: 1.01s\tremaining: 16m 48s\n",
      "100:\tlearn: 1.0000000\ttest: 0.5431405\tbest: 0.5501963 (55)\ttotal: 1m 40s\tremaining: 14m 55s\n",
      "200:\tlearn: 1.0000000\ttest: 0.5633929\tbest: 0.5633929 (167)\ttotal: 3m 16s\tremaining: 13m 2s\n",
      "300:\tlearn: 1.0000000\ttest: 0.5512265\tbest: 0.5633929 (167)\ttotal: 4m 55s\tremaining: 11m 25s\n",
      "\n",
      "bestTest = 0.5633928571\n",
      "bestIteration = 167\n",
      "\n",
      "Training on fold [2/3]\n",
      "0:\tlearn: 0.5361439\ttest: 0.3880136\tbest: 0.3880136 (0)\ttotal: 1.06s\tremaining: 17m 42s\n",
      "100:\tlearn: 1.0000000\ttest: 0.4814677\tbest: 0.4925803 (55)\ttotal: 1m 39s\tremaining: 14m 42s\n",
      "200:\tlearn: 1.0000000\ttest: 0.4688460\tbest: 0.4925803 (55)\ttotal: 3m 14s\tremaining: 12m 52s\n",
      "\n",
      "bestTest = 0.4925802918\n",
      "bestIteration = 55\n",
      "\n",
      "     iterations  test-TotalF1-mean  test-TotalF1-std  train-TotalF1-mean  \\\n",
      "167         167            0.53156          0.046384            0.997366   \n",
      "168         168            0.53156          0.046384            0.997366   \n",
      "169         169            0.53156          0.046384            0.997366   \n",
      "170         170            0.53156          0.046384            0.997366   \n",
      "171         171            0.53156          0.046384            0.997366   \n",
      "172         172            0.53156          0.046384            0.997366   \n",
      "173         173            0.53156          0.046384            0.997366   \n",
      "174         174            0.53156          0.046384            0.997366   \n",
      "175         175            0.53156          0.046384            0.997366   \n",
      "176         176            0.53156          0.046384            0.997366   \n",
      "177         177            0.53156          0.046384            0.997366   \n",
      "179         179            0.53156          0.046384            0.997366   \n",
      "180         180            0.53156          0.046384            0.997366   \n",
      "188         188            0.53156          0.046384            0.997366   \n",
      "189         189            0.53156          0.046384            0.997366   \n",
      "190         190            0.53156          0.046384            0.997366   \n",
      "191         191            0.53156          0.046384            0.997366   \n",
      "192         192            0.53156          0.046384            0.997366   \n",
      "\n",
      "     train-TotalF1-std  test-MultiClass-mean  test-MultiClass-std  \\\n",
      "167           0.004562              0.944552             0.067165   \n",
      "168           0.004562              0.943927             0.065480   \n",
      "169           0.004562              0.945333             0.067254   \n",
      "170           0.004562              0.945262             0.067613   \n",
      "171           0.004562              0.945731             0.067611   \n",
      "172           0.004562              0.943664             0.070108   \n",
      "173           0.004562              0.943943             0.070484   \n",
      "174           0.004562              0.942626             0.069742   \n",
      "175           0.004562              0.942850             0.069451   \n",
      "176           0.004562              0.942727             0.069356   \n",
      "177           0.004562              0.942975             0.069652   \n",
      "179           0.004562              0.942663             0.069915   \n",
      "180           0.004562              0.943805             0.069127   \n",
      "188           0.004562              0.944236             0.067396   \n",
      "189           0.004562              0.944840             0.067931   \n",
      "190           0.004562              0.944628             0.068006   \n",
      "191           0.004562              0.944374             0.067956   \n",
      "192           0.004562              0.944368             0.068250   \n",
      "\n",
      "     train-MultiClass-mean  train-MultiClass-std  \n",
      "167               0.039562              0.009424  \n",
      "168               0.039252              0.009417  \n",
      "169               0.038911              0.009338  \n",
      "170               0.038680              0.009438  \n",
      "171               0.038431              0.009557  \n",
      "172               0.038091              0.009582  \n",
      "173               0.037794              0.009523  \n",
      "174               0.037577              0.009622  \n",
      "175               0.037252              0.009601  \n",
      "176               0.037018              0.009612  \n",
      "177               0.036817              0.009692  \n",
      "179               0.036368              0.009799  \n",
      "180               0.036179              0.009870  \n",
      "188               0.034392              0.009897  \n",
      "189               0.034202              0.009920  \n",
      "190               0.034059              0.009998  \n",
      "191               0.033848              0.009978  \n",
      "192               0.033637              0.009935  \n",
      "\n",
      "\n",
      "learning_rate: 0.3\n",
      "\n",
      "Training on fold [0/3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6084210\ttest: 0.3181818\tbest: 0.3181818 (0)\ttotal: 979ms\tremaining: 16m 18s\n",
      "100:\tlearn: 0.9920978\ttest: 0.5413226\tbest: 0.5413226 (75)\ttotal: 1m 40s\tremaining: 14m 54s\n",
      "200:\tlearn: 0.9920978\ttest: 0.5770202\tbest: 0.5770202 (153)\ttotal: 3m 14s\tremaining: 12m 54s\n",
      "300:\tlearn: 0.9920265\ttest: 0.5573517\tbest: 0.5770202 (153)\ttotal: 4m 53s\tremaining: 11m 21s\n",
      "400:\tlearn: 0.9920978\ttest: 0.5573517\tbest: 0.5848253 (346)\ttotal: 6m 28s\tremaining: 9m 40s\n",
      "500:\tlearn: 0.9920265\ttest: 0.5855699\tbest: 0.5855699 (488)\ttotal: 8m 4s\tremaining: 8m 2s\n",
      "600:\tlearn: 0.9920265\ttest: 0.5848253\tbest: 0.5855699 (488)\ttotal: 9m 43s\tremaining: 6m 27s\n",
      "\n",
      "bestTest = 0.5855698899\n",
      "bestIteration = 488\n",
      "\n",
      "Training on fold [1/3]\n",
      "0:\tlearn: 0.5844597\ttest: 0.4078664\tbest: 0.4078664 (0)\ttotal: 993ms\tremaining: 16m 32s\n",
      "100:\tlearn: 1.0000000\ttest: 0.5816801\tbest: 0.5816801 (100)\ttotal: 1m 44s\tremaining: 15m 32s\n",
      "200:\tlearn: 1.0000000\ttest: 0.6317498\tbest: 0.6317498 (183)\ttotal: 3m 20s\tremaining: 13m 18s\n",
      "300:\tlearn: 1.0000000\ttest: 0.6317498\tbest: 0.6317498 (183)\ttotal: 4m 57s\tremaining: 11m 30s\n",
      "400:\tlearn: 1.0000000\ttest: 0.6578303\tbest: 0.6578303 (318)\ttotal: 6m 38s\tremaining: 9m 55s\n",
      "500:\tlearn: 1.0000000\ttest: 0.6578303\tbest: 0.6578303 (318)\ttotal: 8m 15s\tremaining: 8m 13s\n",
      "\n",
      "bestTest = 0.6578303063\n",
      "bestIteration = 318\n",
      "\n",
      "Training on fold [2/3]\n",
      "0:\tlearn: 0.5361439\ttest: 0.3880136\tbest: 0.3880136 (0)\ttotal: 1.07s\tremaining: 17m 53s\n",
      "100:\tlearn: 1.0000000\ttest: 0.4247903\tbest: 0.5076280 (27)\ttotal: 1m 40s\tremaining: 14m 51s\n",
      "200:\tlearn: 1.0000000\ttest: 0.4478317\tbest: 0.5076280 (27)\ttotal: 3m 22s\tremaining: 13m 25s\n",
      "\n",
      "bestTest = 0.5076279754\n",
      "bestIteration = 27\n",
      "\n",
      "     iterations  test-TotalF1-mean  test-TotalF1-std  train-TotalF1-mean  \\\n",
      "493         493           0.563744          0.106687            0.997342   \n",
      "494         494           0.563744          0.106687            0.997342   \n",
      "496         496           0.563744          0.106687            0.997342   \n",
      "498         498           0.563744          0.106687            0.997342   \n",
      "499         499           0.563744          0.106687            0.997342   \n",
      "500         500           0.563744          0.106687            0.997342   \n",
      "501         501           0.563744          0.106687            0.997342   \n",
      "502         502           0.563744          0.106687            0.997342   \n",
      "503         503           0.563744          0.106687            0.997342   \n",
      "504         504           0.563744          0.106687            0.997342   \n",
      "505         505           0.563744          0.106687            0.997342   \n",
      "506         506           0.563744          0.106687            0.997342   \n",
      "507         507           0.563744          0.106687            0.997342   \n",
      "508         508           0.563744          0.106687            0.997342   \n",
      "509         509           0.563744          0.106687            0.997342   \n",
      "510         510           0.563744          0.106687            0.997342   \n",
      "511         511           0.563744          0.106687            0.997342   \n",
      "512         512           0.563744          0.106687            0.997342   \n",
      "513         513           0.563744          0.106687            0.997342   \n",
      "514         514           0.563744          0.106687            0.997342   \n",
      "531         531           0.563744          0.106687            0.997342   \n",
      "533         533           0.563744          0.106687            0.997342   \n",
      "534         534           0.563744          0.106687            0.997342   \n",
      "539         539           0.563744          0.106687            0.997342   \n",
      "540         540           0.563744          0.106687            0.997342   \n",
      "541         541           0.563744          0.106687            0.997342   \n",
      "542         542           0.563744          0.106687            0.997342   \n",
      "543         543           0.563744          0.106687            0.997342   \n",
      "544         544           0.563744          0.106687            0.997342   \n",
      "545         545           0.563744          0.106687            0.997342   \n",
      "546         546           0.563744          0.106687            0.997342   \n",
      "561         561           0.563744          0.106687            0.997342   \n",
      "\n",
      "     train-TotalF1-std  test-MultiClass-mean  test-MultiClass-std  \\\n",
      "493           0.004603              1.021789             0.031026   \n",
      "494           0.004603              1.022035             0.031364   \n",
      "496           0.004603              1.023363             0.032612   \n",
      "498           0.004603              1.023637             0.032987   \n",
      "499           0.004603              1.023597             0.032619   \n",
      "500           0.004603              1.023581             0.032441   \n",
      "501           0.004603              1.023647             0.032603   \n",
      "502           0.004603              1.023620             0.032587   \n",
      "503           0.004603              1.023881             0.032700   \n",
      "504           0.004603              1.023839             0.032589   \n",
      "505           0.004603              1.024043             0.033200   \n",
      "506           0.004603              1.024185             0.033146   \n",
      "507           0.004603              1.023968             0.033098   \n",
      "508           0.004603              1.024005             0.033126   \n",
      "509           0.004603              1.024046             0.032869   \n",
      "510           0.004603              1.023965             0.033055   \n",
      "511           0.004603              1.024074             0.032882   \n",
      "512           0.004603              1.024601             0.033608   \n",
      "513           0.004603              1.024476             0.033678   \n",
      "514           0.004603              1.024498             0.033869   \n",
      "531           0.004603              1.024788             0.034243   \n",
      "533           0.004603              1.024732             0.034148   \n",
      "534           0.004603              1.024833             0.034320   \n",
      "539           0.004603              1.024577             0.033885   \n",
      "540           0.004603              1.024866             0.034375   \n",
      "541           0.004603              1.025002             0.034605   \n",
      "542           0.004603              1.025004             0.034609   \n",
      "543           0.004603              1.024537             0.033818   \n",
      "544           0.004603              1.024439             0.033651   \n",
      "545           0.004603              1.025139             0.034839   \n",
      "546           0.004603              1.025155             0.034865   \n",
      "561           0.004603              1.025566             0.035563   \n",
      "\n",
      "     train-MultiClass-mean  train-MultiClass-std  \n",
      "493               0.012666              0.007512  \n",
      "494               0.012657              0.007509  \n",
      "496               0.012627              0.007495  \n",
      "498               0.012603              0.007481  \n",
      "499               0.012598              0.007484  \n",
      "500               0.012587              0.007479  \n",
      "501               0.012580              0.007481  \n",
      "502               0.012576              0.007484  \n",
      "503               0.012567              0.007483  \n",
      "504               0.012561              0.007484  \n",
      "505               0.012552              0.007477  \n",
      "506               0.012548              0.007478  \n",
      "507               0.012539              0.007478  \n",
      "508               0.012523              0.007473  \n",
      "509               0.012516              0.007476  \n",
      "510               0.012508              0.007475  \n",
      "511               0.012497              0.007468  \n",
      "512               0.012483              0.007460  \n",
      "513               0.012476              0.007457  \n",
      "514               0.012467              0.007454  \n",
      "531               0.012385              0.007373  \n",
      "533               0.012380              0.007365  \n",
      "534               0.012377              0.007361  \n",
      "539               0.012362              0.007339  \n",
      "540               0.012355              0.007330  \n",
      "541               0.012349              0.007321  \n",
      "542               0.012348              0.007320  \n",
      "543               0.012346              0.007317  \n",
      "544               0.012345              0.007316  \n",
      "545               0.012337              0.007304  \n",
      "546               0.012324              0.007285  \n",
      "561               0.012242              0.007169  \n",
      "\n",
      "\n",
      "learning_rate: 0.4\n",
      "\n",
      "Training on fold [0/3]\n",
      "0:\tlearn: 0.6084210\ttest: 0.3181818\tbest: 0.3181818 (0)\ttotal: 1s\tremaining: 16m 40s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100:\tlearn: 0.9920978\ttest: 0.4807296\tbest: 0.5014436 (98)\ttotal: 1m 41s\tremaining: 15m 1s\n",
      "200:\tlearn: 0.9920265\ttest: 0.5035354\tbest: 0.5058804 (132)\ttotal: 3m 16s\tremaining: 13m 1s\n",
      "300:\tlearn: 0.9920265\ttest: 0.5058804\tbest: 0.5058804 (132)\ttotal: 4m 52s\tremaining: 11m 20s\n",
      "\n",
      "bestTest = 0.5058803635\n",
      "bestIteration = 132\n",
      "\n",
      "Training on fold [1/3]\n",
      "0:\tlearn: 0.5844597\ttest: 0.4078664\tbest: 0.4078664 (0)\ttotal: 982ms\tremaining: 16m 20s\n",
      "100:\tlearn: 1.0000000\ttest: 0.5283283\tbest: 0.5522978 (61)\ttotal: 1m 41s\tremaining: 15m 6s\n",
      "200:\tlearn: 1.0000000\ttest: 0.5964744\tbest: 0.6303158 (189)\ttotal: 3m 16s\tremaining: 13m 2s\n",
      "300:\tlearn: 1.0000000\ttest: 0.5964744\tbest: 0.6303158 (189)\ttotal: 4m 56s\tremaining: 11m 27s\n",
      "\n",
      "bestTest = 0.6303158471\n",
      "bestIteration = 189\n",
      "\n",
      "Training on fold [2/3]\n",
      "0:\tlearn: 0.5361439\ttest: 0.3880136\tbest: 0.3880136 (0)\ttotal: 1.07s\tremaining: 17m 49s\n",
      "100:\tlearn: 1.0000000\ttest: 0.5483084\tbest: 0.5483084 (98)\ttotal: 1m 40s\tremaining: 14m 53s\n",
      "200:\tlearn: 1.0000000\ttest: 0.5263930\tbest: 0.5499004 (104)\ttotal: 3m 18s\tremaining: 13m 8s\n",
      "300:\tlearn: 1.0000000\ttest: 0.5263930\tbest: 0.5499004 (104)\ttotal: 5m 10s\tremaining: 12m 2s\n",
      "\n",
      "bestTest = 0.5499004381\n",
      "bestIteration = 104\n",
      "\n",
      "     iterations  test-TotalF1-mean  test-TotalF1-std  train-TotalF1-mean  \\\n",
      "159         159           0.555194          0.059127            0.997366   \n",
      "\n",
      "     train-TotalF1-std  test-MultiClass-mean  test-MultiClass-std  \\\n",
      "159           0.004562              1.056175             0.113796   \n",
      "\n",
      "     train-MultiClass-mean  train-MultiClass-std  \n",
      "159               0.020157              0.009619  \n",
      "\n",
      "\n",
      "learning_rate: 0.5\n",
      "\n",
      "Training on fold [0/3]\n",
      "0:\tlearn: 0.6084210\ttest: 0.3181818\tbest: 0.3181818 (0)\ttotal: 1.8s\tremaining: 29m 59s\n",
      "100:\tlearn: 0.9920265\ttest: 0.5120662\tbest: 0.5196502 (31)\ttotal: 1m 51s\tremaining: 16m 29s\n",
      "200:\tlearn: 0.9920265\ttest: 0.5848253\tbest: 0.5848253 (200)\ttotal: 3m 28s\tremaining: 13m 50s\n",
      "300:\tlearn: 0.9920978\ttest: 0.5665752\tbest: 0.5848253 (200)\ttotal: 5m 3s\tremaining: 11m 45s\n",
      "400:\tlearn: 0.9920978\ttest: 0.5665752\tbest: 0.5848253 (200)\ttotal: 6m 42s\tremaining: 10m 1s\n",
      "\n",
      "bestTest = 0.5848252641\n",
      "bestIteration = 200\n",
      "\n",
      "Training on fold [1/3]\n",
      "0:\tlearn: 0.5844597\ttest: 0.4078664\tbest: 0.4078664 (0)\ttotal: 1.27s\tremaining: 21m 6s\n",
      "100:\tlearn: 1.0000000\ttest: 0.5707656\tbest: 0.5978393 (64)\ttotal: 1m 42s\tremaining: 15m 8s\n",
      "200:\tlearn: 1.0000000\ttest: 0.5820786\tbest: 0.5978393 (64)\ttotal: 3m 18s\tremaining: 13m 7s\n",
      "\n",
      "bestTest = 0.5978392738\n",
      "bestIteration = 64\n",
      "\n",
      "Training on fold [2/3]\n",
      "0:\tlearn: 0.5361439\ttest: 0.3880136\tbest: 0.3880136 (0)\ttotal: 1.09s\tremaining: 18m 9s\n",
      "100:\tlearn: 1.0000000\ttest: 0.5821151\tbest: 0.5821151 (47)\ttotal: 1m 48s\tremaining: 16m 2s\n",
      "200:\tlearn: 1.0000000\ttest: 0.5580682\tbest: 0.5821151 (47)\ttotal: 3m 34s\tremaining: 14m 13s\n",
      "\n",
      "bestTest = 0.5821150892\n",
      "bestIteration = 47\n",
      "\n",
      "     iterations  test-TotalF1-mean  test-TotalF1-std  train-TotalF1-mean  \\\n",
      "167         167           0.578919          0.007687            0.997366   \n",
      "\n",
      "     train-TotalF1-std  test-MultiClass-mean  test-MultiClass-std  \\\n",
      "167           0.004562              1.038023               0.0791   \n",
      "\n",
      "     train-MultiClass-mean  train-MultiClass-std  \n",
      "167               0.015264              0.008888  \n",
      "\n",
      "\n",
      "learning_rate: 0.6\n",
      "\n",
      "Training on fold [0/3]\n",
      "0:\tlearn: 0.6084210\ttest: 0.3181818\tbest: 0.3181818 (0)\ttotal: 1.24s\tremaining: 20m 42s\n",
      "100:\tlearn: 0.9920978\ttest: 0.5287322\tbest: 0.5287322 (49)\ttotal: 1m 42s\tremaining: 15m 12s\n",
      "200:\tlearn: 0.9920978\ttest: 0.5498191\tbest: 0.5498191 (129)\ttotal: 3m 19s\tremaining: 13m 14s\n",
      "300:\tlearn: 0.9920978\ttest: 0.5498191\tbest: 0.5498191 (129)\ttotal: 4m 55s\tremaining: 11m 25s\n",
      "\n",
      "bestTest = 0.5498191387\n",
      "bestIteration = 129\n",
      "\n",
      "Training on fold [1/3]\n",
      "0:\tlearn: 0.5844597\ttest: 0.4078664\tbest: 0.4078664 (0)\ttotal: 990ms\tremaining: 16m 28s\n",
      "100:\tlearn: 1.0000000\ttest: 0.4414336\tbest: 0.4881351 (20)\ttotal: 1m 40s\tremaining: 14m 50s\n",
      "200:\tlearn: 1.0000000\ttest: 0.4414336\tbest: 0.4881351 (20)\ttotal: 3m 16s\tremaining: 12m 59s\n",
      "\n",
      "bestTest = 0.4881351112\n",
      "bestIteration = 20\n",
      "\n",
      "Training on fold [2/3]\n",
      "0:\tlearn: 0.5361439\ttest: 0.3880136\tbest: 0.3880136 (0)\ttotal: 1.66s\tremaining: 27m 40s\n",
      "100:\tlearn: 1.0000000\ttest: 0.5326770\tbest: 0.5431233 (60)\ttotal: 1m 36s\tremaining: 14m 21s\n",
      "200:\tlearn: 1.0000000\ttest: 0.5105350\tbest: 0.5431233 (60)\ttotal: 3m 19s\tremaining: 13m 12s\n",
      "\n",
      "bestTest = 0.5431232904\n",
      "bestIteration = 60\n",
      "\n",
      "     iterations  test-TotalF1-mean  test-TotalF1-std  train-TotalF1-mean  \\\n",
      "131         131           0.507977          0.058262            0.997366   \n",
      "132         132           0.507977          0.058262            0.997366   \n",
      "133         133           0.507977          0.058262            0.997366   \n",
      "134         134           0.507977          0.058262            0.997366   \n",
      "\n",
      "     train-TotalF1-std  test-MultiClass-mean  test-MultiClass-std  \\\n",
      "131           0.004562              1.138426             0.101514   \n",
      "132           0.004562              1.138588             0.101774   \n",
      "133           0.004562              1.139927             0.100905   \n",
      "134           0.004562              1.141739             0.103182   \n",
      "\n",
      "     train-MultiClass-mean  train-MultiClass-std  \n",
      "131               0.016604              0.009238  \n",
      "132               0.016524              0.009286  \n",
      "133               0.016393              0.009235  \n",
      "134               0.016298              0.009206  \n",
      "\n",
      "\n",
      "learning_rate: 0.7\n",
      "\n",
      "Training on fold [0/3]\n",
      "0:\tlearn: 0.6084210\ttest: 0.3181818\tbest: 0.3181818 (0)\ttotal: 1s\tremaining: 16m 39s\n",
      "100:\tlearn: 0.9920265\ttest: 0.5096437\tbest: 0.5112233 (69)\ttotal: 1m 42s\tremaining: 15m 15s\n",
      "200:\tlearn: 0.9920978\ttest: 0.4985666\tbest: 0.5112233 (69)\ttotal: 3m 24s\tremaining: 13m 32s\n",
      "\n",
      "bestTest = 0.5112233446\n",
      "bestIteration = 69\n",
      "\n",
      "Training on fold [1/3]\n",
      "0:\tlearn: 0.5844597\ttest: 0.4078664\tbest: 0.4078664 (0)\ttotal: 1.82s\tremaining: 30m 16s\n",
      "100:\tlearn: 1.0000000\ttest: 0.5658235\tbest: 0.5658235 (88)\ttotal: 1m 42s\tremaining: 15m 11s\n",
      "200:\tlearn: 1.0000000\ttest: 0.5658235\tbest: 0.5665334 (136)\ttotal: 3m 16s\tremaining: 13m\n",
      "300:\tlearn: 1.0000000\ttest: 0.5658235\tbest: 0.5665334 (136)\ttotal: 4m 51s\tremaining: 11m 17s\n",
      "\n",
      "bestTest = 0.5665334302\n",
      "bestIteration = 136\n",
      "\n",
      "Training on fold [2/3]\n",
      "0:\tlearn: 0.5361439\ttest: 0.3880136\tbest: 0.3880136 (0)\ttotal: 1.05s\tremaining: 17m 34s\n",
      "100:\tlearn: 1.0000000\ttest: 0.5312945\tbest: 0.6031710 (77)\ttotal: 1m 43s\tremaining: 15m 21s\n",
      "200:\tlearn: 1.0000000\ttest: 0.5532439\tbest: 0.6031710 (77)\ttotal: 3m 29s\tremaining: 13m 53s\n",
      "\n",
      "bestTest = 0.6031710225\n",
      "bestIteration = 77\n",
      "\n",
      "     iterations  test-TotalF1-mean  test-TotalF1-std  train-TotalF1-mean  \\\n",
      "136         136           0.556356          0.043026            0.997342   \n",
      "137         137           0.556356          0.043026            0.997342   \n",
      "138         138           0.556356          0.043026            0.997342   \n",
      "\n",
      "     train-TotalF1-std  test-MultiClass-mean  test-MultiClass-std  \\\n",
      "136           0.004603              1.179338             0.121607   \n",
      "137           0.004603              1.180751             0.122597   \n",
      "138           0.004603              1.182586             0.125379   \n",
      "\n",
      "     train-MultiClass-mean  train-MultiClass-std  \n",
      "136               0.013822              0.008903  \n",
      "137               0.013738              0.008864  \n",
      "138               0.013636              0.008838  \n",
      "\n",
      "\n",
      "learning_rate: 0.8\n",
      "\n",
      "Training on fold [0/3]\n",
      "0:\tlearn: 0.6084210\ttest: 0.3181818\tbest: 0.3181818 (0)\ttotal: 2.02s\tremaining: 33m 38s\n",
      "100:\tlearn: 0.9920978\ttest: 0.4979798\tbest: 0.5001482 (99)\ttotal: 1m 44s\tremaining: 15m 28s\n",
      "200:\tlearn: 0.9920265\ttest: 0.5213725\tbest: 0.5318859 (191)\ttotal: 3m 21s\tremaining: 13m 21s\n",
      "300:\tlearn: 0.9920978\ttest: 0.5108003\tbest: 0.5318859 (191)\ttotal: 5m 2s\tremaining: 11m 42s\n",
      "\n",
      "bestTest = 0.5318859415\n",
      "bestIteration = 191\n",
      "\n",
      "Training on fold [1/3]\n",
      "0:\tlearn: 0.5844597\ttest: 0.4078664\tbest: 0.4078664 (0)\ttotal: 1.01s\tremaining: 16m 50s\n",
      "100:\tlearn: 1.0000000\ttest: 0.5961907\tbest: 0.5977183 (44)\ttotal: 1m 40s\tremaining: 14m 56s\n",
      "200:\tlearn: 1.0000000\ttest: 0.5961907\tbest: 0.5977183 (44)\ttotal: 3m 20s\tremaining: 13m 17s\n",
      "\n",
      "bestTest = 0.597718254\n",
      "bestIteration = 44\n",
      "\n",
      "Training on fold [2/3]\n",
      "0:\tlearn: 0.5361439\ttest: 0.3880136\tbest: 0.3880136 (0)\ttotal: 1.18s\tremaining: 19m 36s\n",
      "100:\tlearn: 1.0000000\ttest: 0.5202826\tbest: 0.5202826 (97)\ttotal: 1m 45s\tremaining: 15m 43s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200:\tlearn: 1.0000000\ttest: 0.5156469\tbest: 0.5408955 (157)\ttotal: 3m 26s\tremaining: 13m 39s\n",
      "300:\tlearn: 1.0000000\ttest: 0.5408955\tbest: 0.5408955 (157)\ttotal: 5m 7s\tremaining: 11m 52s\n",
      "\n",
      "bestTest = 0.5408955458\n",
      "bestIteration = 157\n",
      "\n",
      "     iterations  test-TotalF1-mean  test-TotalF1-std  train-TotalF1-mean  \\\n",
      "191         191           0.556324          0.034818            0.997342   \n",
      "192         192           0.556324          0.034818            0.997342   \n",
      "193         193           0.556324          0.034818            0.997342   \n",
      "\n",
      "     train-TotalF1-std  test-MultiClass-mean  test-MultiClass-std  \\\n",
      "191           0.004603              1.211266             0.219364   \n",
      "192           0.004603              1.210718             0.218967   \n",
      "193           0.004603              1.211919             0.219745   \n",
      "\n",
      "     train-MultiClass-mean  train-MultiClass-std  \n",
      "191               0.010078              0.008647  \n",
      "192               0.010042              0.008643  \n",
      "193               0.010018              0.008643  \n",
      "\n",
      "\n",
      "learning_rate: 0.9\n",
      "\n",
      "Training on fold [0/3]\n",
      "0:\tlearn: 0.6084210\ttest: 0.3181818\tbest: 0.3181818 (0)\ttotal: 1.03s\tremaining: 17m 12s\n",
      "100:\tlearn: 0.9920265\ttest: 0.5344988\tbest: 0.5344988 (91)\ttotal: 1m 41s\tremaining: 15m 3s\n",
      "200:\tlearn: 0.9920978\ttest: 0.5650128\tbest: 0.5650128 (194)\ttotal: 3m 15s\tremaining: 12m 55s\n",
      "300:\tlearn: 0.9920265\ttest: 0.5650128\tbest: 0.5650128 (194)\ttotal: 4m 48s\tremaining: 11m 10s\n",
      "400:\tlearn: 0.9920265\ttest: 0.5833399\tbest: 0.5833399 (303)\ttotal: 6m 22s\tremaining: 9m 31s\n",
      "500:\tlearn: 0.9920265\ttest: 0.5640217\tbest: 0.5833399 (303)\ttotal: 8m\tremaining: 7m 58s\n",
      "\n",
      "bestTest = 0.5833398924\n",
      "bestIteration = 303\n",
      "\n",
      "Training on fold [1/3]\n",
      "0:\tlearn: 0.5844597\ttest: 0.4078664\tbest: 0.4078664 (0)\ttotal: 984ms\tremaining: 16m 23s\n",
      "100:\tlearn: 1.0000000\ttest: 0.5288657\tbest: 0.5401387 (16)\ttotal: 1m 33s\tremaining: 13m 54s\n",
      "200:\tlearn: 1.0000000\ttest: 0.5551111\tbest: 0.5551111 (154)\ttotal: 3m 4s\tremaining: 12m 14s\n",
      "300:\tlearn: 1.0000000\ttest: 0.5551111\tbest: 0.5551111 (154)\ttotal: 4m 49s\tremaining: 11m 12s\n",
      "\n",
      "bestTest = 0.5551110732\n",
      "bestIteration = 154\n",
      "\n",
      "Training on fold [2/3]\n",
      "0:\tlearn: 0.5361439\ttest: 0.3880136\tbest: 0.3880136 (0)\ttotal: 1.24s\tremaining: 20m 34s\n",
      "100:\tlearn: 1.0000000\ttest: 0.5807064\tbest: 0.5807064 (67)\ttotal: 1m 43s\tremaining: 15m 17s\n",
      "200:\tlearn: 1.0000000\ttest: 0.5604839\tbest: 0.5807064 (67)\ttotal: 3m 22s\tremaining: 13m 23s\n",
      "\n",
      "bestTest = 0.5807064108\n",
      "bestIteration = 67\n",
      "\n",
      "     iterations  test-TotalF1-mean  test-TotalF1-std  train-TotalF1-mean  \\\n",
      "303         303           0.566312           0.01499            0.997342   \n",
      "308         308           0.566312           0.01499            0.997342   \n",
      "309         309           0.566312           0.01499            0.997342   \n",
      "310         310           0.566312           0.01499            0.997342   \n",
      "311         311           0.566312           0.01499            0.997342   \n",
      "312         312           0.566312           0.01499            0.997342   \n",
      "313         313           0.566312           0.01499            0.997342   \n",
      "314         314           0.566312           0.01499            0.997342   \n",
      "315         315           0.566312           0.01499            0.997342   \n",
      "316         316           0.566312           0.01499            0.997342   \n",
      "317         317           0.566312           0.01499            0.997342   \n",
      "320         320           0.566312           0.01499            0.997342   \n",
      "321         321           0.566312           0.01499            0.997342   \n",
      "335         335           0.566312           0.01499            0.997342   \n",
      "337         337           0.566312           0.01499            0.997342   \n",
      "347         347           0.566312           0.01499            0.997342   \n",
      "348         348           0.566312           0.01499            0.997342   \n",
      "349         349           0.566312           0.01499            0.997342   \n",
      "350         350           0.566312           0.01499            0.997342   \n",
      "351         351           0.566312           0.01499            0.997342   \n",
      "352         352           0.566312           0.01499            0.997342   \n",
      "353         353           0.566312           0.01499            0.997342   \n",
      "354         354           0.566312           0.01499            0.997342   \n",
      "355         355           0.566312           0.01499            0.997342   \n",
      "356         356           0.566312           0.01499            0.997342   \n",
      "357         357           0.566312           0.01499            0.997366   \n",
      "358         358           0.566312           0.01499            0.997366   \n",
      "359         359           0.566312           0.01499            0.997366   \n",
      "360         360           0.566312           0.01499            0.997366   \n",
      "361         361           0.566312           0.01499            0.997366   \n",
      "362         362           0.566312           0.01499            0.997366   \n",
      "363         363           0.566312           0.01499            0.997366   \n",
      "364         364           0.566312           0.01499            0.997366   \n",
      "365         365           0.566312           0.01499            0.997366   \n",
      "366         366           0.566312           0.01499            0.997366   \n",
      "368         368           0.566312           0.01499            0.997366   \n",
      "369         369           0.566312           0.01499            0.997366   \n",
      "370         370           0.566312           0.01499            0.997366   \n",
      "371         371           0.566312           0.01499            0.997366   \n",
      "372         372           0.566312           0.01499            0.997366   \n",
      "373         373           0.566312           0.01499            0.997366   \n",
      "374         374           0.566312           0.01499            0.997366   \n",
      "375         375           0.566312           0.01499            0.997366   \n",
      "376         376           0.566312           0.01499            0.997366   \n",
      "377         377           0.566312           0.01499            0.997366   \n",
      "378         378           0.566312           0.01499            0.997366   \n",
      "379         379           0.566312           0.01499            0.997366   \n",
      "380         380           0.566312           0.01499            0.997366   \n",
      "381         381           0.566312           0.01499            0.997366   \n",
      "382         382           0.566312           0.01499            0.997366   \n",
      "393         393           0.566312           0.01499            0.997366   \n",
      "399         399           0.566312           0.01499            0.997366   \n",
      "400         400           0.566312           0.01499            0.997342   \n",
      "\n",
      "     train-TotalF1-std  test-MultiClass-mean  test-MultiClass-std  \\\n",
      "303           0.004603              1.215176             0.129569   \n",
      "308           0.004603              1.216181             0.129295   \n",
      "309           0.004603              1.215501             0.128504   \n",
      "310           0.004603              1.215095             0.128047   \n",
      "311           0.004603              1.214737             0.127345   \n",
      "312           0.004603              1.214868             0.127295   \n",
      "313           0.004603              1.214367             0.126691   \n",
      "314           0.004603              1.214476             0.126905   \n",
      "315           0.004603              1.214533             0.126515   \n",
      "316           0.004603              1.214702             0.126793   \n",
      "317           0.004603              1.214591             0.126104   \n",
      "320           0.004603              1.215191             0.125935   \n",
      "321           0.004603              1.215088             0.126047   \n",
      "335           0.004603              1.216591             0.125455   \n",
      "337           0.004603              1.217407             0.127031   \n",
      "347           0.004603              1.220173             0.130529   \n",
      "348           0.004603              1.220576             0.130720   \n",
      "349           0.004603              1.220748             0.130975   \n",
      "350           0.004603              1.220633             0.130112   \n",
      "351           0.004603              1.221001             0.130719   \n",
      "352           0.004603              1.221089             0.130617   \n",
      "353           0.004603              1.220881             0.129823   \n",
      "354           0.004603              1.221635             0.130552   \n",
      "355           0.004603              1.221600             0.130491   \n",
      "356           0.004603              1.222355             0.131794   \n",
      "357           0.004562              1.222073             0.131309   \n",
      "358           0.004562              1.221492             0.130306   \n",
      "359           0.004562              1.221424             0.130188   \n",
      "360           0.004562              1.220962             0.129390   \n",
      "361           0.004562              1.221195             0.129793   \n",
      "362           0.004562              1.221937             0.131073   \n",
      "363           0.004562              1.221412             0.130167   \n",
      "364           0.004562              1.221401             0.130149   \n",
      "365           0.004562              1.221446             0.130226   \n",
      "366           0.004562              1.221284             0.129946   \n",
      "368           0.004562              1.221183             0.129773   \n",
      "369           0.004562              1.221190             0.129784   \n",
      "370           0.004562              1.221818             0.130868   \n",
      "371           0.004562              1.221753             0.130757   \n",
      "372           0.004562              1.220628             0.128815   \n",
      "373           0.004562              1.220843             0.129186   \n",
      "374           0.004562              1.221034             0.129516   \n",
      "375           0.004562              1.222047             0.131264   \n",
      "376           0.004562              1.221922             0.131047   \n",
      "377           0.004562              1.222010             0.131200   \n",
      "378           0.004562              1.221631             0.130545   \n",
      "379           0.004562              1.221712             0.130685   \n",
      "380           0.004562              1.221861             0.130943   \n",
      "381           0.004562              1.222073             0.131308   \n",
      "382           0.004562              1.222095             0.131346   \n",
      "393           0.004562              1.221347             0.130056   \n",
      "399           0.004562              1.221928             0.131058   \n",
      "400           0.004603              1.222150             0.131440   \n",
      "\n",
      "     train-MultiClass-mean  train-MultiClass-std  \n",
      "303               0.007257              0.007618  \n",
      "308               0.007219              0.007603  \n",
      "309               0.007205              0.007588  \n",
      "310               0.007200              0.007588  \n",
      "311               0.007195              0.007587  \n",
      "312               0.007183              0.007577  \n",
      "313               0.007180              0.007575  \n",
      "314               0.007174              0.007573  \n",
      "315               0.007169              0.007574  \n",
      "316               0.007158              0.007565  \n",
      "317               0.007151              0.007564  \n",
      "320               0.007135              0.007561  \n",
      "321               0.007128              0.007558  \n",
      "335               0.007043              0.007518  \n",
      "337               0.007031              0.007509  \n",
      "347               0.006961              0.007460  \n",
      "348               0.006951              0.007447  \n",
      "349               0.006945              0.007444  \n",
      "350               0.006933              0.007431  \n",
      "351               0.006928              0.007427  \n",
      "352               0.006923              0.007427  \n",
      "353               0.006917              0.007425  \n",
      "354               0.006908              0.007414  \n",
      "355               0.006906              0.007412  \n",
      "356               0.006897              0.007395  \n",
      "357               0.006884              0.007372  \n",
      "358               0.006881              0.007368  \n",
      "359               0.006880              0.007366  \n",
      "360               0.006877              0.007361  \n",
      "361               0.006875              0.007358  \n",
      "362               0.006866              0.007342  \n",
      "363               0.006865              0.007339  \n",
      "364               0.006864              0.007338  \n",
      "365               0.006861              0.007333  \n",
      "366               0.006860              0.007332  \n",
      "368               0.006856              0.007325  \n",
      "369               0.006855              0.007323  \n",
      "370               0.006848              0.007311  \n",
      "371               0.006847              0.007309  \n",
      "372               0.006842              0.007300  \n",
      "373               0.006840              0.007298  \n",
      "374               0.006839              0.007295  \n",
      "375               0.006828              0.007277  \n",
      "376               0.006827              0.007275  \n",
      "377               0.006823              0.007268  \n",
      "378               0.006821              0.007263  \n",
      "379               0.006819              0.007261  \n",
      "380               0.006810              0.007245  \n",
      "381               0.006808              0.007241  \n",
      "382               0.006806              0.007238  \n",
      "393               0.006777              0.007188  \n",
      "399               0.006763              0.007163  \n",
      "400               0.006756              0.007151  \n"
     ]
    }
   ],
   "source": [
    "lr_list = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "for i in lr_list:\n",
    "    params = {\n",
    "    'learning_rate': i,\n",
    "    'iterations': 1000,\n",
    "    'eval_metric': 'TotalF1',\n",
    "    'early_stopping_rounds': 200,\n",
    "    'use_best_model': True,\n",
    "    'verbose': 100,\n",
    "    'loss_function': 'MultiClass'\n",
    "    }\n",
    "    \n",
    "    print()\n",
    "    print()\n",
    "    print('learning_rate:', i)\n",
    "    print()\n",
    "    scores = cv(learn_pool,\n",
    "                params,\n",
    "                fold_count=3,\n",
    "                )\n",
    "    \n",
    "    print(scores[scores['test-TotalF1-mean'] == scores['test-TotalF1-mean'].max()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6f7864",
   "metadata": {},
   "source": [
    "По результатам кросс-валидации лучше всех показал себя гипер-параметр `learning_rate` со значением `0.5` - F1-мера составила `0.5789`.\n",
    "Зададим основные параметры модели, обучим ее и посмотрим на результаты по категориям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a62d4911",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'iterations': 1000,\n",
    "    'learning_rate': 0.5,\n",
    "    'eval_metric': 'TotalF1',\n",
    "    'early_stopping_rounds': 200,\n",
    "    'use_best_model': True,\n",
    "    'verbose': 100,\n",
    "    'loss_function': 'MultiClass',\n",
    "    'score_function': 'L2'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4c63dd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.7081878\ttest: 0.5910731\tbest: 0.5910731 (0)\ttotal: 13.6s\tremaining: 3h 46m 39s\n",
      "100:\tlearn: 0.9948063\ttest: 0.6706111\tbest: 0.6706111 (75)\ttotal: 2m 11s\tremaining: 19m 33s\n",
      "200:\tlearn: 0.9948063\ttest: 0.6827628\tbest: 0.6827628 (138)\ttotal: 4m 3s\tremaining: 16m 7s\n",
      "300:\tlearn: 0.9948063\ttest: 0.6827628\tbest: 0.6827628 (138)\ttotal: 6m 6s\tremaining: 14m 12s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.6827627757\n",
      "bestIteration = 138\n",
      "\n",
      "Shrink model to first 139 iterations.\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       A1-A2      0.600     0.375     0.462         8\n",
      "          B1      0.778     0.438     0.560        16\n",
      "          B2      0.700     0.921     0.795        38\n",
      "       C1-C2      1.000     0.333     0.500         3\n",
      "\n",
      "    accuracy                          0.708        65\n",
      "   macro avg      0.769     0.517     0.579        65\n",
      "weighted avg      0.721     0.708     0.683        65\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = CatBoostClassifier(**params)\n",
    "model.fit(learn_pool, eval_set=test_pool)\n",
    "print()\n",
    "predictions = model.predict(test_pool)\n",
    "print()\n",
    "print(metrics.classification_report(y_test, predictions, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a9aad7",
   "metadata": {},
   "source": [
    "Максимальный `F1`составил `0.68`, при этом мы видим, что, в целом, по категории `A1-A2` показатель `F1` не дотягивает даже до значения `0.5`. Это значит, что по данной категонии наша модель предсказывает хуже, чем предсказала бы брошенная монетка."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46202bd",
   "metadata": {},
   "source": [
    "## 4. Предсказание уровня английского языка для загружаемых субтитров"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43282c03",
   "metadata": {},
   "source": [
    "Пожалуйста, укажите путь к вашему файлу с субтитрами (.srt):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "62217814",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\yulia\\OneDrive\\Документы\\С рабочего стола\\Проекты\\Workshop_2\\English_scores\\Test\\Toy_Story_1995_2160p_UHD_BluRay_REMUX_HDR10_HEVC_Atmos_7_1_OMEGA.srt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cc9e72d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['A1-A2']]\n"
     ]
    }
   ],
   "source": [
    "# Загрузка .srt\n",
    "# Создать df с колокой Path, вставить туда путь к файлу\n",
    "df_check = pd.DataFrame({'Path': [path]})\n",
    "df_check['Srt'] = df_check.apply(add_column_srt, axis=1)\n",
    "\n",
    "df_check['Srt'] = df_check.apply(replace_str, axis=1)\n",
    "\n",
    "# Лемматизация\n",
    "df_check['Srt'] = df_check['Srt'].apply(lemmatize)\n",
    "df_check['Srt'] = df_check['Srt'].apply(lem_back)\n",
    "\n",
    "docs_ch = np.array(df_check['Srt'])\n",
    "\n",
    "df_ch = pd.DataFrame(pipe.transform(docs_ch).toarray())\n",
    "\n",
    "pool = Pool(\n",
    "    df_ch\n",
    ")\n",
    "\n",
    "# Предсказание\n",
    "prediction = model.predict(pool)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc33472",
   "metadata": {},
   "source": [
    "# Вывод\n",
    "В рамках данного проекта:\n",
    "- Получены, загружены и обработаны вводные данные.\n",
    "- Проведена очистка текстового содержания, лемматизация и избавление от стоп-слов.\n",
    "- Оценена релевантность слов с помощью частотно-обратной частоты термина в документе с помощью tfidf.\n",
    "- Проведена кросс-валидация с оценкой средней `F1`.\n",
    "- Реализовано ML решение, позволяющее предсказывать уровень английского языка по загружаемым субтитрам.\n",
    "- Для проверки загружаемого субтитра добавлена возможность использовать tfidf на базе данных обучения с поощью `pipeline`.\n",
    "\n",
    "В рамках анализа результатов различных подходов результат `F1`в размере `0.68` остается наиболее высоким, при этом по категории `A1-A2` показатель `F1` не дотягивает даже до значения `0.5`. Поэтому, для улучшения качества модели, как область для развития проекта, мы видим возможность рассмотреть другие подходы для лемматизации, оценки релевантности слов, а также более глубокого анализа при чистке субтитров."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
